{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bbc8dc-77bf-4330-8019-b568766082f8",
   "metadata": {},
   "source": [
    "# Scrape Table Data for U.S. Air Force Bases and Installations for Active Duty, National Guard, and Reserve from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1e11c-7cf4-42ce-bc06-58cab2f6e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaaed84-1391-4188-8dd9-7b03aadfb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch browser\n",
    "browser = Browser ('chrome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574d6f5-beaf-472a-ae8e-04b317485c29",
   "metadata": {},
   "source": [
    "## Step 1: Visit the Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbc3f6-72bc-4d8f-8563-bde98de2ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the website\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_United_States_Air_Force_installations'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fe43e-db19-4567-9610-a8bf83240e20",
   "metadata": {},
   "source": [
    "## Step 2: Scrape the Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce67b6-2e9e-4f4f-9f4d-95ba0d989fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Beautiful Soup\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "tables = soup.find_all('table', class_='wikitable sortable jquery-tablesorter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5569b-62ae-45dd-8665-0fcc6f35b35d",
   "metadata": {},
   "source": [
    "## Step 3: Store the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644614d0-8492-475d-a8ec-3cf68ff2c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold data from both tables\n",
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1754b8e-750a-4058-b90d-e4aa0085d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize header names\n",
    "def standardize_header_name(header):\n",
    "    return header.replace(' ', '_').replace('-', '_').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca8b19-5d41-4b8c-a14f-2d4ddf07baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each table and append the data\n",
    "for index, table in enumerate(tables[:2]): # Limit to the first two tables\n",
    "    \n",
    "    # Extract header row\n",
    "    header_row = table.find('tr')\n",
    "    headers = [standardize_header_name(th.text.strip()) for th in header_row.find_all('th')]\n",
    "    \n",
    "    # Extract data rows and append to all_data with a table identifier\n",
    "    rows = []\n",
    "    for tr in table.find_all('tr')[1:]:  # skip the first row as it contains headers\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "        if cells:\n",
    "            rows.append(cells)\n",
    "\n",
    "    # Save each table to DataFrame then append to all_data list\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fb92b-7436-4e52-86c1-1bb3f9ac2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify table data for Table 1 - AFB, Active Duty Locations\n",
    "active_duty_df = all_data[0]\n",
    "active_duty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7da1c3-c821-4b4f-9643-efb2af1c8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify table data for Table 2 - AFB, National Guard and Reserve Locations\n",
    "reserve_df = all_data[1]\n",
    "reserve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09894de-cb9c-449e-93c2-a97c1c570826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'state' column without reassigning to a new variable\n",
    "reserve_df.rename(columns={'state': 'state_or_area'}, inplace=True)\n",
    "reserve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bcdeb-21de-4025-aeda-c6d672c5bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that column headers match in both tables\n",
    "print(\"Active Duty DF Columns:\", active_duty_df.columns)\n",
    "print(\"Reserve DF Columns:\", reserve_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be35138-d18a-45c3-ac70-f5901c82a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([active_duty_df, reserve_df], ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5cbf3-c3f2-489f-979d-3233e9c37ab0",
   "metadata": {},
   "source": [
    "## Step 4: Clean the DataFrame\n",
    "\n",
    "### Step 4a: Split the 'Coordinates' column into two new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4b725-58f2-46e4-a8cc-288f8b7e23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'coordinates' column into two new columns\n",
    "split_df = combined_df['coordinates'].str.split(' / ', expand=True)\n",
    "\n",
    "# Ensure there are always two columns\n",
    "if split_df.shape[1] == 1:\n",
    "    \n",
    "    # Add a second column with NaN if only one column resulted from the split\n",
    "    split_df[1] = pd.NA\n",
    "\n",
    "# Assign split columns to the original DataFrame\n",
    "combined_df['dms_coordinates'] = split_df[0]\n",
    "combined_df['decimal_coordinates'] = split_df[1]\n",
    "\n",
    "# Print the DataFrame to verify the output\n",
    "print(combined_df[['dms_coordinates', 'decimal_coordinates']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7a941-360c-4738-8522-cf743ebb1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the maximum width of the column to, say, 1000 characters\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "coordinates = combined_df['coordinates']\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dcf615-1138-49ea-b2f5-14e006617d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'coordinates' column into potentially three parts\n",
    "split_columns = combined_df['coordinates'].str.split(' / ', expand=True)\n",
    "\n",
    "# Assign these new columns back to the original DataFrame\n",
    "combined_df['dms_coordinates'] = split_columns[0]\n",
    "\n",
    "# Safely assign second part if it exists\n",
    "combined_df['decimal_coordinates'] = split_columns[1] if split_columns.shape[1] > 1 else pd.NA\n",
    "\n",
    "# Safely assign third part if it exists\n",
    "combined_df['geojson_coordinates'] = split_columns[2] if split_columns.shape[1] > 2 else pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533062fa-028e-4127-b1b2-774563aa1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3283b-7827-4af9-a50f-cbd5d1070a53",
   "metadata": {},
   "source": [
    "### Step 4b: Extract just the numeral from 'decimal_coordinates' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e2773-f9b7-45cb-a10d-2d6596eb9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and convert the 'decimal_coordinates' column by extracting just the numeral\n",
    "def clean_and_format_coords(coord):\n",
    "    \n",
    "    if pd.isna(coord):\n",
    "        return None  # Handle missing values\n",
    "    \n",
    "    # Extract numbers and potential N, S, E, W characters\n",
    "    parts = re.findall(r'([+-]?\\d+\\.\\d+)([NSEW]?)', coord)\n",
    "    \n",
    "    if not parts:\n",
    "        return None\n",
    "    \n",
    "    # Prepare latitude and longitude, considering the direction\n",
    "    cleaned_parts = []\n",
    "    \n",
    "    for value, direction in parts:\n",
    "        num = float(value)\n",
    "\n",
    "        # South or West should be negative\n",
    "        if direction == 'S' or direction == 'W':\n",
    "            num = -num\n",
    "        cleaned_parts.append(num)\n",
    "    \n",
    "    if len(cleaned_parts) == 2:\n",
    "        # Ensure longitude comes first for GeoJSON\n",
    "        return (cleaned_parts[1], cleaned_parts[0])\n",
    "    return None\n",
    "\n",
    "# Apply this cleaning and formatting to the DataFrame\n",
    "combined_df['geojson_coordinates'] = combined_df['decimal_coordinates'].apply(clean_and_format_coords)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257bcd6-9150-48e8-b65e-8ef093840e54",
   "metadata": {},
   "source": [
    "### Step 4c: Split the newly created 'geojson_coordinates' column into separate 'longitude' and 'latitude' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f7d0f-3185-4839-b59c-38aac4a56a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'geojson_coordinates' into 'longitude' and 'latitude'\n",
    "combined_df['longitude'], combined_df['latitude'] = zip(*combined_df['geojson_coordinates'])\n",
    "\n",
    "# Print the updated DataFrame to check the new columns\n",
    "print(combined_df[['longitude', 'latitude']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53f1e7-51d3-4174-829c-7868857ff423",
   "metadata": {},
   "source": [
    "## Step 5: Clean the DataFrame by dropping unnecessary columns, such as all the 'coordinates' and the 'emblem' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcf61d-9128-45aa-93c9-e5a17b7f03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are no longer needed\n",
    "combined_df = active_duty_df.drop(columns=[\n",
    "    'coordinates', \n",
    "    'wing_or_unit_emblem', \n",
    "    'dms_coordinates', \n",
    "    'decimal_coordinates', \n",
    "    'geojson_coordinates'\n",
    "])\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af8b37-2843-4394-8475-16aab30df987",
   "metadata": {},
   "source": [
    "## Step 6: Save the DataFrame as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11a0d6-581a-47e5-9921-edb1659a79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to a JSON string\n",
    "json_str = combined_df.to_json(orient='records')\n",
    "\n",
    "# Parse the JSON string back into a Python list of dictionaries\n",
    "data = json.loads(json_str)\n",
    "\n",
    "# Write the JSON file with indentation for better readability\n",
    "with open('air_force_base_us.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "# Optionally, print the JSON string to the console for verification\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244b562-e665-450d-87de-327d61c07e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
